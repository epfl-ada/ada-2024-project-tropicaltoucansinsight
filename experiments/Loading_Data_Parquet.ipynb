{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "728c80017d4f49c49d62e4c2ba054d6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load video metadata\n",
    "\n",
    "chunks_0 = []\n",
    "chunks_1 = []\n",
    "chunks_2 = []\n",
    "chunks_3 = []\n",
    "chunks_4 = []\n",
    "chunks_5 = []\n",
    "chunks_6 = []\n",
    "chunks_7 = []\n",
    "chunks_8 = []\n",
    "chunks_9 = []\n",
    "chunks_10 = []\n",
    "chunks_11 = []\n",
    "chunks_12 = []\n",
    "chunks_13 = []\n",
    "\n",
    "\n",
    "# Define the chunk size\n",
    "chunk_size = 5000  # adjust based on memory availability\n",
    "\n",
    "counter = 0\n",
    "\n",
    "# Read the JSONL file in chunks\n",
    "for chunk in tqdm(pd.read_json('YouNiverse\\yt_metadata_en.jsonl.gz', lines=True, chunksize=chunk_size)):\n",
    "    i = counter//1000\n",
    "    globals()[f'chunks_{i}'].append(chunk)\n",
    "    counter += 1\n",
    "\n",
    "\n",
    "for i in tqdm(range(14)):\n",
    "    name = f'df_video_meta_{i}'\n",
    "    globals()[name] = pd.concat(globals()[f'chunks_{i}'], ignore_index=True)\n",
    "\n",
    "# Concatenate all chunks into a single DataFrame after the loop\n",
    "#df_video_meta = pd.concat(chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "An error occurred while calling the read_json method registered to the pandas backend.\nOriginal Message: An error occurred while calling the read_json method registered to the pandas backend.\nOriginal Message: ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\MaxLo\\anaconda3\\envs\\VisualStudio\\Lib\\site-packages\\dask\\backends.py:140\u001b[0m, in \u001b[0;36mCreationDispatch.register_inplace.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\MaxLo\\anaconda3\\envs\\VisualStudio\\Lib\\site-packages\\dask\\dataframe\\io\\json.py:291\u001b[0m, in \u001b[0;36mread_json\u001b[1;34m(url_path, orient, lines, storage_options, blocksize, sample, encoding, errors, compression, meta, engine, include_path_column, path_converter, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m     parts \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    278\u001b[0m         delayed(read_json_file)(\n\u001b[0;32m    279\u001b[0m             f,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    288\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m files\n\u001b[0;32m    289\u001b[0m     ]\n\u001b[1;32m--> 291\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m from_delayed(parts, meta\u001b[38;5;241m=\u001b[39mmeta)\n",
      "File \u001b[1;32mc:\\Users\\MaxLo\\anaconda3\\envs\\VisualStudio\\Lib\\site-packages\\dask\\dataframe\\io\\io.py:644\u001b[0m, in \u001b[0;36mfrom_delayed\u001b[1;34m(dfs, meta, divisions, prefix, verify_meta)\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m meta \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 644\u001b[0m     meta \u001b[38;5;241m=\u001b[39m delayed(make_meta)(dfs[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[0;32m    645\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\MaxLo\\anaconda3\\envs\\VisualStudio\\Lib\\site-packages\\dask\\base.py:376\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[0;32m    354\u001b[0m \n\u001b[0;32m    355\u001b[0m \u001b[38;5;124;03mThis turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;124;03mdask.compute\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 376\u001b[0m (result,) \u001b[38;5;241m=\u001b[39m compute(\u001b[38;5;28mself\u001b[39m, traverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\MaxLo\\anaconda3\\envs\\VisualStudio\\Lib\\site-packages\\dask\\base.py:664\u001b[0m, in \u001b[0;36mcompute\u001b[1;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[0;32m    663\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[1;32m--> 664\u001b[0m     results \u001b[38;5;241m=\u001b[39m schedule(dsk, keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[1;32mc:\\Users\\MaxLo\\anaconda3\\envs\\VisualStudio\\Lib\\site-packages\\dask\\dataframe\\io\\json.py:311\u001b[0m, in \u001b[0;36mread_json_file\u001b[1;34m(f, orient, lines, engine, column_name, path, path_dtype, kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m f \u001b[38;5;28;01mas\u001b[39;00m open_file:\n\u001b[1;32m--> 311\u001b[0m     df \u001b[38;5;241m=\u001b[39m engine(open_file, orient\u001b[38;5;241m=\u001b[39morient, lines\u001b[38;5;241m=\u001b[39mlines, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m column_name:\n",
      "File \u001b[1;32mc:\\Users\\MaxLo\\anaconda3\\envs\\VisualStudio\\Lib\\site-packages\\pandas\\io\\json\\_json.py:791\u001b[0m, in \u001b[0;36mread_json\u001b[1;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[0;32m    789\u001b[0m     convert_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 791\u001b[0m json_reader \u001b[38;5;241m=\u001b[39m JsonReader(\n\u001b[0;32m    792\u001b[0m     path_or_buf,\n\u001b[0;32m    793\u001b[0m     orient\u001b[38;5;241m=\u001b[39morient,\n\u001b[0;32m    794\u001b[0m     typ\u001b[38;5;241m=\u001b[39mtyp,\n\u001b[0;32m    795\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    796\u001b[0m     convert_axes\u001b[38;5;241m=\u001b[39mconvert_axes,\n\u001b[0;32m    797\u001b[0m     convert_dates\u001b[38;5;241m=\u001b[39mconvert_dates,\n\u001b[0;32m    798\u001b[0m     keep_default_dates\u001b[38;5;241m=\u001b[39mkeep_default_dates,\n\u001b[0;32m    799\u001b[0m     precise_float\u001b[38;5;241m=\u001b[39mprecise_float,\n\u001b[0;32m    800\u001b[0m     date_unit\u001b[38;5;241m=\u001b[39mdate_unit,\n\u001b[0;32m    801\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m    802\u001b[0m     lines\u001b[38;5;241m=\u001b[39mlines,\n\u001b[0;32m    803\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m    804\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m    805\u001b[0m     nrows\u001b[38;5;241m=\u001b[39mnrows,\n\u001b[0;32m    806\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    807\u001b[0m     encoding_errors\u001b[38;5;241m=\u001b[39mencoding_errors,\n\u001b[0;32m    808\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    809\u001b[0m     engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[0;32m    810\u001b[0m )\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize:\n",
      "File \u001b[1;32mc:\\Users\\MaxLo\\anaconda3\\envs\\VisualStudio\\Lib\\site-packages\\pandas\\io\\json\\_json.py:905\u001b[0m, in \u001b[0;36mJsonReader.__init__\u001b[1;34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, lines, chunksize, compression, nrows, storage_options, encoding_errors, dtype_backend, engine)\u001b[0m\n\u001b[0;32m    904\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_data_from_filepath(filepath_or_buffer)\n\u001b[1;32m--> 905\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess_data(data)\n",
      "File \u001b[1;32mc:\\Users\\MaxLo\\anaconda3\\envs\\VisualStudio\\Lib\\site-packages\\pandas\\io\\json\\_json.py:917\u001b[0m, in \u001b[0;36mJsonReader._preprocess_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    916\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 917\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunksize \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnrows):\n",
      "File \u001b[1;32mc:\\Users\\MaxLo\\anaconda3\\envs\\VisualStudio\\Lib\\gzip.py:301\u001b[0m, in \u001b[0;36mGzipFile.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(errno\u001b[38;5;241m.\u001b[39mEBADF, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread() on write-only GzipFile object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 301\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer\u001b[38;5;241m.\u001b[39mread(size)\n",
      "File \u001b[1;32mc:\\Users\\MaxLo\\anaconda3\\envs\\VisualStudio\\Lib\\_compression.py:121\u001b[0m, in \u001b[0;36mDecompressReader.readall\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    119\u001b[0m     chunks\u001b[38;5;241m.\u001b[39mappend(data)\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(chunks)\n",
      "\u001b[1;31mMemoryError\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\MaxLo\\anaconda3\\envs\\VisualStudio\\Lib\\site-packages\\dask\\backends.py:140\u001b[0m, in \u001b[0;36mCreationDispatch.register_inplace.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\MaxLo\\anaconda3\\envs\\VisualStudio\\Lib\\site-packages\\dask_expr\\io\\json.py:101\u001b[0m, in \u001b[0;36mread_json\u001b[1;34m(url_path, orient, lines, storage_options, blocksize, sample, encoding, errors, compression, meta, engine, include_path_column, path_converter, **kwargs)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjson\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read_json\n\u001b[1;32m--> 101\u001b[0m df \u001b[38;5;241m=\u001b[39m read_json(\n\u001b[0;32m    102\u001b[0m     url_path,\n\u001b[0;32m    103\u001b[0m     orient\u001b[38;5;241m=\u001b[39morient,\n\u001b[0;32m    104\u001b[0m     lines\u001b[38;5;241m=\u001b[39mlines,\n\u001b[0;32m    105\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    106\u001b[0m     blocksize\u001b[38;5;241m=\u001b[39mblocksize,\n\u001b[0;32m    107\u001b[0m     sample\u001b[38;5;241m=\u001b[39msample,\n\u001b[0;32m    108\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m    109\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    110\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m    111\u001b[0m     meta\u001b[38;5;241m=\u001b[39mmeta,\n\u001b[0;32m    112\u001b[0m     engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[0;32m    113\u001b[0m     include_path_column\u001b[38;5;241m=\u001b[39minclude_path_column,\n\u001b[0;32m    114\u001b[0m     path_converter\u001b[38;5;241m=\u001b[39mpath_converter,\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    116\u001b[0m )\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m from_legacy_dataframe(df)\n",
      "File \u001b[1;32mc:\\Users\\MaxLo\\anaconda3\\envs\\VisualStudio\\Lib\\site-packages\\dask\\backends.py:151\u001b[0m, in \u001b[0;36mCreationDispatch.register_inplace.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 151\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mMemoryError\u001b[0m: An error occurred while calling the read_json method registered to the pandas backend.\nOriginal Message: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_video_meta_dask \u001b[38;5;241m=\u001b[39m dd\u001b[38;5;241m.\u001b[39mread_json(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYouNiverse/yt_metadata_en.jsonl.gz\u001b[39m\u001b[38;5;124m'\u001b[39m, lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\MaxLo\\anaconda3\\envs\\VisualStudio\\Lib\\site-packages\\dask\\backends.py:151\u001b[0m, in \u001b[0;36mCreationDispatch.register_inplace.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 151\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mMemoryError\u001b[0m: An error occurred while calling the read_json method registered to the pandas backend.\nOriginal Message: An error occurred while calling the read_json method registered to the pandas backend.\nOriginal Message: "
     ]
    }
   ],
   "source": [
    "# Stopped running due to memory error\n",
    "df_video_meta_dask = dd.read_json('YouNiverse/yt_metadata_en.jsonl.gz', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8d220f060564a2e97a0545f49de0352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Define the chunk size (adjust based on memory availability)\n",
    "chunk_size = 10000000\n",
    "\n",
    "# Output Parquet file path (base name for individual files)\n",
    "output_file_base = 'processed_data_chunk_'\n",
    "\n",
    "# Initialize a counter for chunks\n",
    "counter = 0\n",
    "\n",
    "# Read the JSONL file in chunks\n",
    "for chunk in tqdm(pd.read_json('YouNiverse/yt_metadata_en.jsonl.gz', lines=True, chunksize=chunk_size)):\n",
    "    # Process each chunk as needed\n",
    "    # Here you can apply any processing to the chunk\n",
    "\n",
    "    # Save the chunk to a Parquet file\n",
    "    chunk.to_parquet(f\"{output_file_base}{counter}.parquet\", index=False)\n",
    "\n",
    "    # Increment the counter\n",
    "    counter += 1\n",
    "    print(f\"Processed and saved chunk {counter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First convert to parquet\n",
    "import pyarrow.json as pj\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Read JSONL and convert to Parquet\n",
    "input_file = \"YouNiverse/yt_metadata_en.jsonl.gz\"\n",
    "output_file = \"YouNiverse/yt_metadata.parquet\"\n",
    "\n",
    "table = pj.read_json(input_file)\n",
    "pq.write_table(table, output_file)\n",
    "\n",
    "# Now read the Parquet file with dask\n",
    "import dask.dataframe as dd\n",
    "df = dd.read_parquet(output_file)\n",
    "\n",
    "# Ran for 37 min without success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Java gateway process exited before sending its port number",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Initialize a Spark session\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m spark \u001b[38;5;241m=\u001b[39m SparkSession\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39mappName(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLargeJSONProcessing\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mgetOrCreate()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Read the JSON file\u001b[39;00m\n\u001b[0;32m      7\u001b[0m df \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39mjson(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYouNiverse/yt_metadata_en.jsonl.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\MaxLo\\anaconda3\\envs\\VisualStudio\\Lib\\site-packages\\pyspark\\sql\\session.py:477\u001b[0m, in \u001b[0;36mSparkSession.Builder.getOrCreate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    475\u001b[0m     sparkConf\u001b[38;5;241m.\u001b[39mset(key, value)\n\u001b[0;32m    476\u001b[0m \u001b[38;5;66;03m# This SparkContext may be an existing one.\u001b[39;00m\n\u001b[1;32m--> 477\u001b[0m sc \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39mgetOrCreate(sparkConf)\n\u001b[0;32m    478\u001b[0m \u001b[38;5;66;03m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[39;00m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;66;03m# by all sessions.\u001b[39;00m\n\u001b[0;32m    480\u001b[0m session \u001b[38;5;241m=\u001b[39m SparkSession(sc, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options)\n",
      "File \u001b[1;32mc:\\Users\\MaxLo\\anaconda3\\envs\\VisualStudio\\Lib\\site-packages\\pyspark\\context.py:512\u001b[0m, in \u001b[0;36mSparkContext.getOrCreate\u001b[1;34m(cls, conf)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 512\u001b[0m         SparkContext(conf\u001b[38;5;241m=\u001b[39mconf \u001b[38;5;129;01mor\u001b[39;00m SparkConf())\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\n",
      "File \u001b[1;32mc:\\Users\\MaxLo\\anaconda3\\envs\\VisualStudio\\Lib\\site-packages\\pyspark\\context.py:198\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gateway \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m gateway\u001b[38;5;241m.\u001b[39mgateway_parameters\u001b[38;5;241m.\u001b[39mauth_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    194\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to pass an insecure Py4j gateway to Spark. This\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    195\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is not allowed as it is a security risk.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    196\u001b[0m     )\n\u001b[1;32m--> 198\u001b[0m SparkContext\u001b[38;5;241m.\u001b[39m_ensure_initialized(\u001b[38;5;28mself\u001b[39m, gateway\u001b[38;5;241m=\u001b[39mgateway, conf\u001b[38;5;241m=\u001b[39mconf)\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_init(\n\u001b[0;32m    201\u001b[0m         master,\n\u001b[0;32m    202\u001b[0m         appName,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    212\u001b[0m         memory_profiler_cls,\n\u001b[0;32m    213\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\MaxLo\\anaconda3\\envs\\VisualStudio\\Lib\\site-packages\\pyspark\\context.py:432\u001b[0m, in \u001b[0;36mSparkContext._ensure_initialized\u001b[1;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_gateway:\n\u001b[1;32m--> 432\u001b[0m         SparkContext\u001b[38;5;241m.\u001b[39m_gateway \u001b[38;5;241m=\u001b[39m gateway \u001b[38;5;129;01mor\u001b[39;00m launch_gateway(conf)\n\u001b[0;32m    433\u001b[0m         SparkContext\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39m_gateway\u001b[38;5;241m.\u001b[39mjvm\n\u001b[0;32m    435\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m instance:\n",
      "File \u001b[1;32mc:\\Users\\MaxLo\\anaconda3\\envs\\VisualStudio\\Lib\\site-packages\\pyspark\\java_gateway.py:106\u001b[0m, in \u001b[0;36mlaunch_gateway\u001b[1;34m(conf, popen_kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(conn_info_file):\n\u001b[1;32m--> 106\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJava gateway process exited before sending its port number\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(conn_info_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m info:\n\u001b[0;32m    109\u001b[0m     gateway_port \u001b[38;5;241m=\u001b[39m read_int(info)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Java gateway process exited before sending its port number"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize a Spark session\n",
    "spark = SparkSession.builder.appName(\"LargeJSONProcessing\").getOrCreate()\n",
    "\n",
    "# Read the JSON file\n",
    "df = spark.read.json(\"YouNiverse/yt_metadata_en.jsonl.gz\")\n",
    "\n",
    "# Convert to pandas DataFrame if necessary (or continue processing with Spark)\n",
    "#pdf = filtered_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "from itertools import islice\n",
    "\n",
    "# Define function to process a certain number of lines of the dataset\n",
    "def process_jsonl_chunks(file_path, start_line=0, end_line=None, chunk_size=5000, output_parquet_file=None):\n",
    "    \"\"\"\n",
    "    Reads a compressed JSON Lines file from a specific line range in chunks,\n",
    "    processes each chunk, and optionally saves it to a Parquet file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the .jsonl.gz file.\n",
    "        start_line (int): Line number to start reading from.\n",
    "        end_line (int or None): Line number to stop reading at. If None, reads to the end.\n",
    "        chunk_size (int): Number of lines per chunk.\n",
    "        output_parquet_file (str): Path to save Parquet file. If None, does not save.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    with gzip.open(file_path, 'rt') as file:  # 'rt' for text mode with gzip\n",
    "        # Skip to the start line\n",
    "        print(\"Going to specified start line..\")\n",
    "        for _ in tqdm(range(start_line)):\n",
    "            next(file)\n",
    "        \n",
    "        # Initialize a line counter\n",
    "        current_line = start_line\n",
    "\n",
    "        # Define dataframe to be returned\n",
    "        df = []\n",
    "\n",
    "        print(\"Getting chunks..\")\n",
    "        # Process the file in chunks until reaching end_line\n",
    "        for i, chunk in enumerate(iter(lambda: list(islice(file, chunk_size)), [])):\n",
    "            # Check if we're within the specified line range\n",
    "            if end_line is not None and current_line >= end_line:\n",
    "                break  # Stop if we've reached or exceeded the end line\n",
    "\n",
    "            # Adjust the chunk size if it exceeds end_line\n",
    "            if end_line is not None:\n",
    "                chunk = chunk[: max(0, end_line - current_line)]\n",
    "            \n",
    "            # Convert the chunk to a DataFrame\n",
    "            data = [json.loads(line) for line in chunk]\n",
    "            df.append(pd.DataFrame(data))\n",
    "\n",
    "            # Update current line\n",
    "            current_line += len(chunk)\n",
    "        \n",
    "        print(\"Concatenating..\")\n",
    "        return pd.concat(df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count lines of a JSON Lines file\n",
    "def count_lines_in_chunks(file_path, chunk_size=100000):\n",
    "    count = 0\n",
    "    with gzip.open(file_path, 'rt') as file:\n",
    "        while True:\n",
    "            lines = file.readlines(chunk_size)  # Read a chunk of lines\n",
    "            if not lines:\n",
    "                break\n",
    "            count += len(lines)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'YouNiverse/yt_metadata_en.jsonl.gz'\n",
    "#num_lines = count_lines_in_chunks(file_path=filepath)\n",
    "#print(num_lines)\n",
    "# There are as many lines as there are videos in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to specified start line..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb8e965c3fc848e9b2fd85d95c4dac12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting chunks..\n",
      "Concatenating..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MaxLo\\AppData\\Local\\Temp\\ipykernel_26848\\1242293564.py:53: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat(df, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# End line is not included\n",
    "\n",
    "# Loading data for first 20'000'000 videos\n",
    "df_video_meta_1 = process_jsonl_chunks(file_path=filepath, start_line=0, end_line=20000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_video_meta_1.tail(5)\n",
    "df_video_meta_1.to_parquet(path='YouNiverse/df_video_meta_1.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_video_meta_1_parquet = pd.read_parquet(path='YouNiverse/df_video_meta_1.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categories</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>crawl_date</th>\n",
       "      <th>description</th>\n",
       "      <th>dislike_count</th>\n",
       "      <th>display_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>like_count</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>view_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19999995</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UCbzt7jamo0xA0WKPX3Ut-rw</td>\n",
       "      <td>2019-11-15 03:58:54.691949</td>\n",
       "      <td>FACEBOOK PAGE\\nhttps://www.facebook.com/JamesH...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>jnfFTj85L8E</td>\n",
       "      <td>310</td>\n",
       "      <td>308.0</td>\n",
       "      <td>02,Escape,From,The,Tavern,James,Horner</td>\n",
       "      <td>02 - Escape From The Tavern - James Horner - W...</td>\n",
       "      <td>2011-07-21 00:00:00</td>\n",
       "      <td>123004.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999996</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UCbzt7jamo0xA0WKPX3Ut-rw</td>\n",
       "      <td>2019-11-15 03:58:55.296351</td>\n",
       "      <td>FACEBOOK PAGE\\nhttps://www.facebook.com/JamesH...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>pRskpDvjrIM</td>\n",
       "      <td>590</td>\n",
       "      <td>1346.0</td>\n",
       "      <td>01,Elora,Danan,James,Horner</td>\n",
       "      <td>01 - Elora Danan - James Horner - Willow</td>\n",
       "      <td>2011-07-21 00:00:00</td>\n",
       "      <td>308625.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999997</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UCbzt7jamo0xA0WKPX3Ut-rw</td>\n",
       "      <td>2019-11-15 03:58:55.940956</td>\n",
       "      <td>FACEBOOK PAGE\\nhttps://www.facebook.com/JamesH...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>SqggGvm_9a8</td>\n",
       "      <td>260</td>\n",
       "      <td>31.0</td>\n",
       "      <td>14,See,You,James,Horner</td>\n",
       "      <td>14 - I See You - Leona Lewis - James Horner - ...</td>\n",
       "      <td>2011-06-23 00:00:00</td>\n",
       "      <td>3432.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999998</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UCbzt7jamo0xA0WKPX3Ut-rw</td>\n",
       "      <td>2019-11-15 03:58:56.573328</td>\n",
       "      <td>FACEBOOK PAGE\\nhttps://www.facebook.com/JamesH...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Hjc5KhASGhI</td>\n",
       "      <td>680</td>\n",
       "      <td>21.0</td>\n",
       "      <td>13,War,James,Horner</td>\n",
       "      <td>13 - War - James Horner - Avatar</td>\n",
       "      <td>2011-06-23 00:00:00</td>\n",
       "      <td>3590.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999999</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UCbzt7jamo0xA0WKPX3Ut-rw</td>\n",
       "      <td>2019-11-15 03:58:57.067663</td>\n",
       "      <td>FACEBOOK PAGE\\nhttps://www.facebook.com/JamesH...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9j4OXdEJBpc</td>\n",
       "      <td>310</td>\n",
       "      <td>36.0</td>\n",
       "      <td>12,Gathering,All,The,Na'vi,Clans,For,Battle,Ja...</td>\n",
       "      <td>12 - Gathering All The Na'vi Clans For Battle ...</td>\n",
       "      <td>2011-06-23 00:00:00</td>\n",
       "      <td>7562.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                categories                channel_id  \\\n",
       "19999995  Film & Animation  UCbzt7jamo0xA0WKPX3Ut-rw   \n",
       "19999996  Film & Animation  UCbzt7jamo0xA0WKPX3Ut-rw   \n",
       "19999997  Film & Animation  UCbzt7jamo0xA0WKPX3Ut-rw   \n",
       "19999998  Film & Animation  UCbzt7jamo0xA0WKPX3Ut-rw   \n",
       "19999999  Film & Animation  UCbzt7jamo0xA0WKPX3Ut-rw   \n",
       "\n",
       "                          crawl_date  \\\n",
       "19999995  2019-11-15 03:58:54.691949   \n",
       "19999996  2019-11-15 03:58:55.296351   \n",
       "19999997  2019-11-15 03:58:55.940956   \n",
       "19999998  2019-11-15 03:58:56.573328   \n",
       "19999999  2019-11-15 03:58:57.067663   \n",
       "\n",
       "                                                description  dislike_count  \\\n",
       "19999995  FACEBOOK PAGE\\nhttps://www.facebook.com/JamesH...            8.0   \n",
       "19999996  FACEBOOK PAGE\\nhttps://www.facebook.com/JamesH...           36.0   \n",
       "19999997  FACEBOOK PAGE\\nhttps://www.facebook.com/JamesH...            2.0   \n",
       "19999998  FACEBOOK PAGE\\nhttps://www.facebook.com/JamesH...            0.0   \n",
       "19999999  FACEBOOK PAGE\\nhttps://www.facebook.com/JamesH...            4.0   \n",
       "\n",
       "           display_id  duration  like_count  \\\n",
       "19999995  jnfFTj85L8E       310       308.0   \n",
       "19999996  pRskpDvjrIM       590      1346.0   \n",
       "19999997  SqggGvm_9a8       260        31.0   \n",
       "19999998  Hjc5KhASGhI       680        21.0   \n",
       "19999999  9j4OXdEJBpc       310        36.0   \n",
       "\n",
       "                                                       tags  \\\n",
       "19999995             02,Escape,From,The,Tavern,James,Horner   \n",
       "19999996                        01,Elora,Danan,James,Horner   \n",
       "19999997                            14,See,You,James,Horner   \n",
       "19999998                                13,War,James,Horner   \n",
       "19999999  12,Gathering,All,The,Na'vi,Clans,For,Battle,Ja...   \n",
       "\n",
       "                                                      title  \\\n",
       "19999995  02 - Escape From The Tavern - James Horner - W...   \n",
       "19999996           01 - Elora Danan - James Horner - Willow   \n",
       "19999997  14 - I See You - Leona Lewis - James Horner - ...   \n",
       "19999998                   13 - War - James Horner - Avatar   \n",
       "19999999  12 - Gathering All The Na'vi Clans For Battle ...   \n",
       "\n",
       "                  upload_date  view_count  \n",
       "19999995  2011-07-21 00:00:00    123004.0  \n",
       "19999996  2011-07-21 00:00:00    308625.0  \n",
       "19999997  2011-06-23 00:00:00      3432.0  \n",
       "19999998  2011-06-23 00:00:00      3590.0  \n",
       "19999999  2011-06-23 00:00:00      7562.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_video_meta_1_parquet.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_video_meta_1.to_pickle(path='YouNiverse/df_video_meta_1_pickle.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling and read pickle are slower than parqueting and read parquet -> preferably use parquet\n",
    "df_video_meta_1_pickle = pd.read_pickle('YouNiverse/df_video_meta_1_pickle.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categories</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>crawl_date</th>\n",
       "      <th>description</th>\n",
       "      <th>dislike_count</th>\n",
       "      <th>display_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>like_count</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>view_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19999995</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UCbzt7jamo0xA0WKPX3Ut-rw</td>\n",
       "      <td>2019-11-15 03:58:54.691949</td>\n",
       "      <td>FACEBOOK PAGE\\nhttps://www.facebook.com/JamesH...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>jnfFTj85L8E</td>\n",
       "      <td>310</td>\n",
       "      <td>308.0</td>\n",
       "      <td>02,Escape,From,The,Tavern,James,Horner</td>\n",
       "      <td>02 - Escape From The Tavern - James Horner - W...</td>\n",
       "      <td>2011-07-21 00:00:00</td>\n",
       "      <td>123004.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999996</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UCbzt7jamo0xA0WKPX3Ut-rw</td>\n",
       "      <td>2019-11-15 03:58:55.296351</td>\n",
       "      <td>FACEBOOK PAGE\\nhttps://www.facebook.com/JamesH...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>pRskpDvjrIM</td>\n",
       "      <td>590</td>\n",
       "      <td>1346.0</td>\n",
       "      <td>01,Elora,Danan,James,Horner</td>\n",
       "      <td>01 - Elora Danan - James Horner - Willow</td>\n",
       "      <td>2011-07-21 00:00:00</td>\n",
       "      <td>308625.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999997</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UCbzt7jamo0xA0WKPX3Ut-rw</td>\n",
       "      <td>2019-11-15 03:58:55.940956</td>\n",
       "      <td>FACEBOOK PAGE\\nhttps://www.facebook.com/JamesH...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>SqggGvm_9a8</td>\n",
       "      <td>260</td>\n",
       "      <td>31.0</td>\n",
       "      <td>14,See,You,James,Horner</td>\n",
       "      <td>14 - I See You - Leona Lewis - James Horner - ...</td>\n",
       "      <td>2011-06-23 00:00:00</td>\n",
       "      <td>3432.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999998</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UCbzt7jamo0xA0WKPX3Ut-rw</td>\n",
       "      <td>2019-11-15 03:58:56.573328</td>\n",
       "      <td>FACEBOOK PAGE\\nhttps://www.facebook.com/JamesH...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Hjc5KhASGhI</td>\n",
       "      <td>680</td>\n",
       "      <td>21.0</td>\n",
       "      <td>13,War,James,Horner</td>\n",
       "      <td>13 - War - James Horner - Avatar</td>\n",
       "      <td>2011-06-23 00:00:00</td>\n",
       "      <td>3590.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999999</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UCbzt7jamo0xA0WKPX3Ut-rw</td>\n",
       "      <td>2019-11-15 03:58:57.067663</td>\n",
       "      <td>FACEBOOK PAGE\\nhttps://www.facebook.com/JamesH...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9j4OXdEJBpc</td>\n",
       "      <td>310</td>\n",
       "      <td>36.0</td>\n",
       "      <td>12,Gathering,All,The,Na'vi,Clans,For,Battle,Ja...</td>\n",
       "      <td>12 - Gathering All The Na'vi Clans For Battle ...</td>\n",
       "      <td>2011-06-23 00:00:00</td>\n",
       "      <td>7562.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                categories                channel_id  \\\n",
       "19999995  Film & Animation  UCbzt7jamo0xA0WKPX3Ut-rw   \n",
       "19999996  Film & Animation  UCbzt7jamo0xA0WKPX3Ut-rw   \n",
       "19999997  Film & Animation  UCbzt7jamo0xA0WKPX3Ut-rw   \n",
       "19999998  Film & Animation  UCbzt7jamo0xA0WKPX3Ut-rw   \n",
       "19999999  Film & Animation  UCbzt7jamo0xA0WKPX3Ut-rw   \n",
       "\n",
       "                          crawl_date  \\\n",
       "19999995  2019-11-15 03:58:54.691949   \n",
       "19999996  2019-11-15 03:58:55.296351   \n",
       "19999997  2019-11-15 03:58:55.940956   \n",
       "19999998  2019-11-15 03:58:56.573328   \n",
       "19999999  2019-11-15 03:58:57.067663   \n",
       "\n",
       "                                                description  dislike_count  \\\n",
       "19999995  FACEBOOK PAGE\\nhttps://www.facebook.com/JamesH...            8.0   \n",
       "19999996  FACEBOOK PAGE\\nhttps://www.facebook.com/JamesH...           36.0   \n",
       "19999997  FACEBOOK PAGE\\nhttps://www.facebook.com/JamesH...            2.0   \n",
       "19999998  FACEBOOK PAGE\\nhttps://www.facebook.com/JamesH...            0.0   \n",
       "19999999  FACEBOOK PAGE\\nhttps://www.facebook.com/JamesH...            4.0   \n",
       "\n",
       "           display_id  duration  like_count  \\\n",
       "19999995  jnfFTj85L8E       310       308.0   \n",
       "19999996  pRskpDvjrIM       590      1346.0   \n",
       "19999997  SqggGvm_9a8       260        31.0   \n",
       "19999998  Hjc5KhASGhI       680        21.0   \n",
       "19999999  9j4OXdEJBpc       310        36.0   \n",
       "\n",
       "                                                       tags  \\\n",
       "19999995             02,Escape,From,The,Tavern,James,Horner   \n",
       "19999996                        01,Elora,Danan,James,Horner   \n",
       "19999997                            14,See,You,James,Horner   \n",
       "19999998                                13,War,James,Horner   \n",
       "19999999  12,Gathering,All,The,Na'vi,Clans,For,Battle,Ja...   \n",
       "\n",
       "                                                      title  \\\n",
       "19999995  02 - Escape From The Tavern - James Horner - W...   \n",
       "19999996           01 - Elora Danan - James Horner - Willow   \n",
       "19999997  14 - I See You - Leona Lewis - James Horner - ...   \n",
       "19999998                   13 - War - James Horner - Avatar   \n",
       "19999999  12 - Gathering All The Na'vi Clans For Battle ...   \n",
       "\n",
       "                  upload_date  view_count  \n",
       "19999995  2011-07-21 00:00:00    123004.0  \n",
       "19999996  2011-07-21 00:00:00    308625.0  \n",
       "19999997  2011-06-23 00:00:00      3432.0  \n",
       "19999998  2011-06-23 00:00:00      3590.0  \n",
       "19999999  2011-06-23 00:00:00      7562.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_video_meta_1_pickle.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to specified start line..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46f95a46a50f4011a02f030d4977badd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting chunks..\n",
      "Concatenating..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MaxLo\\AppData\\Local\\Temp\\ipykernel_7948\\1242293564.py:53: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat(df, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Loading videos from 20'000'000 to 39'999'999\n",
    "df_video_meta_2 = process_jsonl_chunks(file_path=filepath, start_line=20000000, end_line=40000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categories</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>crawl_date</th>\n",
       "      <th>description</th>\n",
       "      <th>dislike_count</th>\n",
       "      <th>display_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>like_count</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>view_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UCbzt7jamo0xA0WKPX3Ut-rw</td>\n",
       "      <td>2019-11-15 03:58:57.663245</td>\n",
       "      <td>FACEBOOK PAGE\\nhttps://www.facebook.com/JamesH...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7PoK8wW8KZo</td>\n",
       "      <td>170</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11,Shutting,Down,Grace's,Lab,James,Horner</td>\n",
       "      <td>11 - Shutting Down Grace's Lab - James Horner ...</td>\n",
       "      <td>2011-06-23 00:00:00</td>\n",
       "      <td>2152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UCbzt7jamo0xA0WKPX3Ut-rw</td>\n",
       "      <td>2019-11-15 03:58:58.193387</td>\n",
       "      <td>FACEBOOK PAGE\\nhttps://www.facebook.com/JamesH...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9yGTSMiexng</td>\n",
       "      <td>410</td>\n",
       "      <td>67.0</td>\n",
       "      <td>10,The,Destruction,Of,Hometree,James,Horner</td>\n",
       "      <td>10 - The Destruction Of Hometree - James Horne...</td>\n",
       "      <td>2011-06-23 00:00:00</td>\n",
       "      <td>9772.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UCbzt7jamo0xA0WKPX3Ut-rw</td>\n",
       "      <td>2019-11-15 03:58:58.698710</td>\n",
       "      <td>FACEBOOK PAGE\\nhttps://www.facebook.com/JamesH...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>tJ6tOY5S8dA</td>\n",
       "      <td>300</td>\n",
       "      <td>20.0</td>\n",
       "      <td>09,Quaritch,James,Horner</td>\n",
       "      <td>09 - Quaritch - James Horner - Avatar</td>\n",
       "      <td>2011-06-23 00:00:00</td>\n",
       "      <td>7495.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UCbzt7jamo0xA0WKPX3Ut-rw</td>\n",
       "      <td>2019-11-15 03:58:59.253763</td>\n",
       "      <td>FACEBOOK PAGE\\nhttps://www.facebook.com/JamesH...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>WPBk87tSOc4</td>\n",
       "      <td>200</td>\n",
       "      <td>7.0</td>\n",
       "      <td>08,Scorched,Earth,James,Horner</td>\n",
       "      <td>08 - Scorched Earth - James Horner - Avatar</td>\n",
       "      <td>2011-06-23 00:00:00</td>\n",
       "      <td>1776.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UCbzt7jamo0xA0WKPX3Ut-rw</td>\n",
       "      <td>2019-11-15 03:58:59.770408</td>\n",
       "      <td>FACEBOOK PAGE\\nhttps://www.facebook.com/JamesH...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>UkbgdSZemWU</td>\n",
       "      <td>290</td>\n",
       "      <td>20.0</td>\n",
       "      <td>07,Jake's,First,Flight,James,Horner</td>\n",
       "      <td>07 - Jake's First Flight - James Horner - Avatar</td>\n",
       "      <td>2011-06-23 00:00:00</td>\n",
       "      <td>3193.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         categories                channel_id                  crawl_date  \\\n",
       "0  Film & Animation  UCbzt7jamo0xA0WKPX3Ut-rw  2019-11-15 03:58:57.663245   \n",
       "1  Film & Animation  UCbzt7jamo0xA0WKPX3Ut-rw  2019-11-15 03:58:58.193387   \n",
       "2  Film & Animation  UCbzt7jamo0xA0WKPX3Ut-rw  2019-11-15 03:58:58.698710   \n",
       "3  Film & Animation  UCbzt7jamo0xA0WKPX3Ut-rw  2019-11-15 03:58:59.253763   \n",
       "4  Film & Animation  UCbzt7jamo0xA0WKPX3Ut-rw  2019-11-15 03:58:59.770408   \n",
       "\n",
       "                                         description  dislike_count  \\\n",
       "0  FACEBOOK PAGE\\nhttps://www.facebook.com/JamesH...            0.0   \n",
       "1  FACEBOOK PAGE\\nhttps://www.facebook.com/JamesH...            2.0   \n",
       "2  FACEBOOK PAGE\\nhttps://www.facebook.com/JamesH...            1.0   \n",
       "3  FACEBOOK PAGE\\nhttps://www.facebook.com/JamesH...            0.0   \n",
       "4  FACEBOOK PAGE\\nhttps://www.facebook.com/JamesH...            0.0   \n",
       "\n",
       "    display_id  duration  like_count  \\\n",
       "0  7PoK8wW8KZo       170        12.0   \n",
       "1  9yGTSMiexng       410        67.0   \n",
       "2  tJ6tOY5S8dA       300        20.0   \n",
       "3  WPBk87tSOc4       200         7.0   \n",
       "4  UkbgdSZemWU       290        20.0   \n",
       "\n",
       "                                          tags  \\\n",
       "0    11,Shutting,Down,Grace's,Lab,James,Horner   \n",
       "1  10,The,Destruction,Of,Hometree,James,Horner   \n",
       "2                     09,Quaritch,James,Horner   \n",
       "3               08,Scorched,Earth,James,Horner   \n",
       "4          07,Jake's,First,Flight,James,Horner   \n",
       "\n",
       "                                               title          upload_date  \\\n",
       "0  11 - Shutting Down Grace's Lab - James Horner ...  2011-06-23 00:00:00   \n",
       "1  10 - The Destruction Of Hometree - James Horne...  2011-06-23 00:00:00   \n",
       "2              09 - Quaritch - James Horner - Avatar  2011-06-23 00:00:00   \n",
       "3        08 - Scorched Earth - James Horner - Avatar  2011-06-23 00:00:00   \n",
       "4   07 - Jake's First Flight - James Horner - Avatar  2011-06-23 00:00:00   \n",
       "\n",
       "   view_count  \n",
       "0      2152.0  \n",
       "1      9772.0  \n",
       "2      7495.0  \n",
       "3      1776.0  \n",
       "4      3193.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_video_meta_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_video_meta_2.to_parquet(path='YouNiverse/df_video_meta_2.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_video_meta_2_parquet = pd.read_parquet(path='YouNiverse/df_video_meta_2.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categories</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>crawl_date</th>\n",
       "      <th>description</th>\n",
       "      <th>dislike_count</th>\n",
       "      <th>display_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>like_count</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>view_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19999995</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>UCMz7JFeTmiO2oJgtmYhpUmQ</td>\n",
       "      <td>2019-11-10 20:43:47.478141</td>\n",
       "      <td>The night of the Star Wars Premiere, Jesse tri...</td>\n",
       "      <td>2497.0</td>\n",
       "      <td>TBPyu7liNQ0</td>\n",
       "      <td>1575</td>\n",
       "      <td>32750.0</td>\n",
       "      <td>psycho series,psycho dad,psycho,mcjuggernugget...</td>\n",
       "      <td>I AM YOUR FATHER!</td>\n",
       "      <td>2015-12-17 00:00:00</td>\n",
       "      <td>1419226.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999996</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>UCMz7JFeTmiO2oJgtmYhpUmQ</td>\n",
       "      <td>2019-11-10 20:43:48.035144</td>\n",
       "      <td>Hey there, Juggies and non-Juggies! Expect vid...</td>\n",
       "      <td>8343.0</td>\n",
       "      <td>uVMiG6CllbQ</td>\n",
       "      <td>267</td>\n",
       "      <td>33793.0</td>\n",
       "      <td>psycho series,psycho dad,psycho,mcjuggernugget...</td>\n",
       "      <td>Hello, I am McJuggerNuggets! (2016)</td>\n",
       "      <td>2015-12-17 00:00:00</td>\n",
       "      <td>5110665.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999997</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>UCMz7JFeTmiO2oJgtmYhpUmQ</td>\n",
       "      <td>2019-11-10 20:43:48.556228</td>\n",
       "      <td>Jesse and Corn get roped into bringing his Mom...</td>\n",
       "      <td>3145.0</td>\n",
       "      <td>7n9EQuv_8uI</td>\n",
       "      <td>1701</td>\n",
       "      <td>49344.0</td>\n",
       "      <td>psycho series,psycho dad,psycho,mcjuggernugget...</td>\n",
       "      <td>DRUNK DANCE NIGHT!</td>\n",
       "      <td>2015-12-16 00:00:00</td>\n",
       "      <td>1368194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999998</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>UCMz7JFeTmiO2oJgtmYhpUmQ</td>\n",
       "      <td>2019-11-10 20:43:49.214078</td>\n",
       "      <td>In this twenty-third installment of \"McJuggerN...</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>l1Eh0TntG24</td>\n",
       "      <td>204</td>\n",
       "      <td>8336.0</td>\n",
       "      <td>psycho series,psycho dad,psycho,mcjuggernugget...</td>\n",
       "      <td>#MMM23 -- Demons</td>\n",
       "      <td>2015-12-16 00:00:00</td>\n",
       "      <td>237093.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999999</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>UCMz7JFeTmiO2oJgtmYhpUmQ</td>\n",
       "      <td>2019-11-10 20:43:49.812247</td>\n",
       "      <td>Uncle Larry confronts Aunt Melissa about her r...</td>\n",
       "      <td>2437.0</td>\n",
       "      <td>_Slmlm21pRk</td>\n",
       "      <td>1656</td>\n",
       "      <td>33978.0</td>\n",
       "      <td>psycho series,psycho dad,psycho,mcjuggernugget...</td>\n",
       "      <td>LIVING IN THE PAST!</td>\n",
       "      <td>2015-12-15 00:00:00</td>\n",
       "      <td>1536545.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             categories                channel_id                  crawl_date  \\\n",
       "19999995  Entertainment  UCMz7JFeTmiO2oJgtmYhpUmQ  2019-11-10 20:43:47.478141   \n",
       "19999996  Entertainment  UCMz7JFeTmiO2oJgtmYhpUmQ  2019-11-10 20:43:48.035144   \n",
       "19999997  Entertainment  UCMz7JFeTmiO2oJgtmYhpUmQ  2019-11-10 20:43:48.556228   \n",
       "19999998  Entertainment  UCMz7JFeTmiO2oJgtmYhpUmQ  2019-11-10 20:43:49.214078   \n",
       "19999999  Entertainment  UCMz7JFeTmiO2oJgtmYhpUmQ  2019-11-10 20:43:49.812247   \n",
       "\n",
       "                                                description  dislike_count  \\\n",
       "19999995  The night of the Star Wars Premiere, Jesse tri...         2497.0   \n",
       "19999996  Hey there, Juggies and non-Juggies! Expect vid...         8343.0   \n",
       "19999997  Jesse and Corn get roped into bringing his Mom...         3145.0   \n",
       "19999998  In this twenty-third installment of \"McJuggerN...         1440.0   \n",
       "19999999  Uncle Larry confronts Aunt Melissa about her r...         2437.0   \n",
       "\n",
       "           display_id  duration  like_count  \\\n",
       "19999995  TBPyu7liNQ0      1575     32750.0   \n",
       "19999996  uVMiG6CllbQ       267     33793.0   \n",
       "19999997  7n9EQuv_8uI      1701     49344.0   \n",
       "19999998  l1Eh0TntG24       204      8336.0   \n",
       "19999999  _Slmlm21pRk      1656     33978.0   \n",
       "\n",
       "                                                       tags  \\\n",
       "19999995  psycho series,psycho dad,psycho,mcjuggernugget...   \n",
       "19999996  psycho series,psycho dad,psycho,mcjuggernugget...   \n",
       "19999997  psycho series,psycho dad,psycho,mcjuggernugget...   \n",
       "19999998  psycho series,psycho dad,psycho,mcjuggernugget...   \n",
       "19999999  psycho series,psycho dad,psycho,mcjuggernugget...   \n",
       "\n",
       "                                        title          upload_date  view_count  \n",
       "19999995                    I AM YOUR FATHER!  2015-12-17 00:00:00   1419226.0  \n",
       "19999996  Hello, I am McJuggerNuggets! (2016)  2015-12-17 00:00:00   5110665.0  \n",
       "19999997                   DRUNK DANCE NIGHT!  2015-12-16 00:00:00   1368194.0  \n",
       "19999998                     #MMM23 -- Demons  2015-12-16 00:00:00    237093.0  \n",
       "19999999                  LIVING IN THE PAST!  2015-12-15 00:00:00   1536545.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_video_meta_2_parquet.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to specified start line..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f23acf12f0e3418e90c0b1640a984f4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting chunks..\n",
      "Concatenating..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MaxLo\\AppData\\Local\\Temp\\ipykernel_12444\\1242293564.py:53: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat(df, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Loading videos from 40'000'000 to 59'999'999\n",
    "df_video_meta_3 = process_jsonl_chunks(file_path=filepath, start_line=40000000, end_line=60000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_video_meta_3.to_parquet(path='YouNiverse/df_video_meta_3.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowMemoryError",
     "evalue": "malloc of size 4294967296 failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArrowMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_video_meta_3_parquet \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYouNiverse/df_video_meta_3.gz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\MaxLo\\anaconda3\\envs\\VisualStudio\\Lib\\site-packages\\pandas\\io\\parquet.py:667\u001b[0m, in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[0;32m    664\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    665\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[1;32m--> 667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m impl\u001b[38;5;241m.\u001b[39mread(\n\u001b[0;32m    668\u001b[0m     path,\n\u001b[0;32m    669\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m    670\u001b[0m     filters\u001b[38;5;241m=\u001b[39mfilters,\n\u001b[0;32m    671\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    672\u001b[0m     use_nullable_dtypes\u001b[38;5;241m=\u001b[39muse_nullable_dtypes,\n\u001b[0;32m    673\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    674\u001b[0m     filesystem\u001b[38;5;241m=\u001b[39mfilesystem,\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    676\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\MaxLo\\anaconda3\\envs\\VisualStudio\\Lib\\site-packages\\pandas\\io\\parquet.py:281\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[1;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    274\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[0;32m    275\u001b[0m         path_or_handle,\n\u001b[0;32m    276\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 281\u001b[0m     result \u001b[38;5;241m=\u001b[39m pa_table\u001b[38;5;241m.\u001b[39mto_pandas(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mto_pandas_kwargs)\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    284\u001b[0m         result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m_as_manager(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\MaxLo\\anaconda3\\envs\\VisualStudio\\Lib\\site-packages\\pyarrow\\array.pxi:872\u001b[0m, in \u001b[0;36mpyarrow.lib._PandasConvertible.to_pandas\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\MaxLo\\anaconda3\\envs\\VisualStudio\\Lib\\site-packages\\pyarrow\\table.pxi:4904\u001b[0m, in \u001b[0;36mpyarrow.lib.Table._to_pandas\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\MaxLo\\anaconda3\\envs\\VisualStudio\\Lib\\site-packages\\pyarrow\\pandas_compat.py:779\u001b[0m, in \u001b[0;36mtable_to_dataframe\u001b[1;34m(options, table, categories, ignore_metadata, types_mapper)\u001b[0m\n\u001b[0;32m    776\u001b[0m columns \u001b[38;5;241m=\u001b[39m _deserialize_column_index(table, all_columns, column_indexes)\n\u001b[0;32m    778\u001b[0m column_names \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mcolumn_names\n\u001b[1;32m--> 779\u001b[0m result \u001b[38;5;241m=\u001b[39m pa\u001b[38;5;241m.\u001b[39mlib\u001b[38;5;241m.\u001b[39mtable_to_blocks(options, table, categories,\n\u001b[0;32m    780\u001b[0m                                 \u001b[38;5;28mlist\u001b[39m(ext_columns_dtypes\u001b[38;5;241m.\u001b[39mkeys()))\n\u001b[0;32m    781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _pandas_api\u001b[38;5;241m.\u001b[39mis_ge_v3():\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternals\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_dataframe_from_blocks\n",
      "File \u001b[1;32mc:\\Users\\MaxLo\\anaconda3\\envs\\VisualStudio\\Lib\\site-packages\\pyarrow\\table.pxi:3771\u001b[0m, in \u001b[0;36mpyarrow.lib.table_to_blocks\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\MaxLo\\anaconda3\\envs\\VisualStudio\\Lib\\site-packages\\pyarrow\\error.pxi:91\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mArrowMemoryError\u001b[0m: malloc of size 4294967296 failed"
     ]
    }
   ],
   "source": [
    "df_video_meta_3_parquet = pd.read_parquet(path='YouNiverse/df_video_meta_3.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_video_meta_3_parquet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_video_meta_3_parquet\u001b[38;5;241m.\u001b[39mtail()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_video_meta_3_parquet' is not defined"
     ]
    }
   ],
   "source": [
    "df_video_meta_3_parquet.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to specified start line..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a4f3ba03a4d4524bef6ca9ba749925f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting chunks..\n",
      "Concatenating..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MaxLo\\AppData\\Local\\Temp\\ipykernel_8064\\1242293564.py:53: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat(df, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Loading videos from 60'000'000 to 72924794\n",
    "df_video_meta_4 = process_jsonl_chunks(file_path=filepath, start_line=60000000, end_line=72924795)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_video_meta_4.to_parquet(path='YouNiverse/df_video_meta_4.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_video_meta_4_parquet = pd.read_parquet(path='YouNiverse/df_video_meta_4.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categories</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>crawl_date</th>\n",
       "      <th>description</th>\n",
       "      <th>dislike_count</th>\n",
       "      <th>display_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>like_count</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>view_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12924789</th>\n",
       "      <td>News &amp; Politics</td>\n",
       "      <td>UCrwE8kVqtIUVUzKui2WVpuQ</td>\n",
       "      <td>2019-11-01 23:46:02.294620</td>\n",
       "      <td>Shri Manoj Kumar Tiwari's speech during Motion...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>YQLoxwLpjSU</td>\n",
       "      <td>270</td>\n",
       "      <td>67.0</td>\n",
       "      <td>BJP,Bharatiya Janata Party,BJP videos,Yuva TV,...</td>\n",
       "      <td>Shri Manoj Kumar Tiwari's speech during Motion...</td>\n",
       "      <td>2017-02-06 00:00:00</td>\n",
       "      <td>4409.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12924790</th>\n",
       "      <td>News &amp; Politics</td>\n",
       "      <td>UCrwE8kVqtIUVUzKui2WVpuQ</td>\n",
       "      <td>2019-11-01 23:46:06.401481</td>\n",
       "      <td>Shri La Ganesan's speech during Motion of Than...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>mINQHg1QBcg</td>\n",
       "      <td>878</td>\n",
       "      <td>21.0</td>\n",
       "      <td>BJP,Bharatiya Janata Party,BJP videos,Yuva TV,...</td>\n",
       "      <td>Shri La Ganesan's speech during Motion of Than...</td>\n",
       "      <td>2017-02-06 00:00:00</td>\n",
       "      <td>1172.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12924791</th>\n",
       "      <td>News &amp; Politics</td>\n",
       "      <td>UCrwE8kVqtIUVUzKui2WVpuQ</td>\n",
       "      <td>2019-11-01 23:46:09.530822</td>\n",
       "      <td>Shri Mukhtar Abbas Naqvi's speech during Motio...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>x20aNOWh1yI</td>\n",
       "      <td>1003</td>\n",
       "      <td>35.0</td>\n",
       "      <td>BJP,Bharatiya Janata Party,BJP videos,Yuva TV,...</td>\n",
       "      <td>Shri Mukhtar Abbas Naqvi's speech during Motio...</td>\n",
       "      <td>2017-02-06 00:00:00</td>\n",
       "      <td>1898.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12924792</th>\n",
       "      <td>News &amp; Politics</td>\n",
       "      <td>UCrwE8kVqtIUVUzKui2WVpuQ</td>\n",
       "      <td>2019-11-01 23:46:00.080054</td>\n",
       "      <td>BJP submitted complaint to EC against Chief Se...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-Nn6FL2gqEw</td>\n",
       "      <td>755</td>\n",
       "      <td>27.0</td>\n",
       "      <td>BJP,Bharatiya Janata Party,BJP videos,Yuva TV,...</td>\n",
       "      <td>BJP submitted complaint to EC against Chief Se...</td>\n",
       "      <td>2017-02-06 00:00:00</td>\n",
       "      <td>726.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12924793</th>\n",
       "      <td>News &amp; Politics</td>\n",
       "      <td>UCrwE8kVqtIUVUzKui2WVpuQ</td>\n",
       "      <td>2019-11-01 23:46:02.381286</td>\n",
       "      <td>Shri Amit Shah speech at public meeting in Noi...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>7gxEjSoRVgA</td>\n",
       "      <td>1771</td>\n",
       "      <td>327.0</td>\n",
       "      <td>BJP,Bharatiya Janata Party,BJP videos,Yuva TV,...</td>\n",
       "      <td>Shri Amit Shah speech at public meeting in Noi...</td>\n",
       "      <td>2017-02-06 00:00:00</td>\n",
       "      <td>37572.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               categories                channel_id  \\\n",
       "12924789  News & Politics  UCrwE8kVqtIUVUzKui2WVpuQ   \n",
       "12924790  News & Politics  UCrwE8kVqtIUVUzKui2WVpuQ   \n",
       "12924791  News & Politics  UCrwE8kVqtIUVUzKui2WVpuQ   \n",
       "12924792  News & Politics  UCrwE8kVqtIUVUzKui2WVpuQ   \n",
       "12924793  News & Politics  UCrwE8kVqtIUVUzKui2WVpuQ   \n",
       "\n",
       "                          crawl_date  \\\n",
       "12924789  2019-11-01 23:46:02.294620   \n",
       "12924790  2019-11-01 23:46:06.401481   \n",
       "12924791  2019-11-01 23:46:09.530822   \n",
       "12924792  2019-11-01 23:46:00.080054   \n",
       "12924793  2019-11-01 23:46:02.381286   \n",
       "\n",
       "                                                description  dislike_count  \\\n",
       "12924789  Shri Manoj Kumar Tiwari's speech during Motion...            3.0   \n",
       "12924790  Shri La Ganesan's speech during Motion of Than...            0.0   \n",
       "12924791  Shri Mukhtar Abbas Naqvi's speech during Motio...            2.0   \n",
       "12924792  BJP submitted complaint to EC against Chief Se...            0.0   \n",
       "12924793  Shri Amit Shah speech at public meeting in Noi...           31.0   \n",
       "\n",
       "           display_id  duration  like_count  \\\n",
       "12924789  YQLoxwLpjSU       270        67.0   \n",
       "12924790  mINQHg1QBcg       878        21.0   \n",
       "12924791  x20aNOWh1yI      1003        35.0   \n",
       "12924792  -Nn6FL2gqEw       755        27.0   \n",
       "12924793  7gxEjSoRVgA      1771       327.0   \n",
       "\n",
       "                                                       tags  \\\n",
       "12924789  BJP,Bharatiya Janata Party,BJP videos,Yuva TV,...   \n",
       "12924790  BJP,Bharatiya Janata Party,BJP videos,Yuva TV,...   \n",
       "12924791  BJP,Bharatiya Janata Party,BJP videos,Yuva TV,...   \n",
       "12924792  BJP,Bharatiya Janata Party,BJP videos,Yuva TV,...   \n",
       "12924793  BJP,Bharatiya Janata Party,BJP videos,Yuva TV,...   \n",
       "\n",
       "                                                      title  \\\n",
       "12924789  Shri Manoj Kumar Tiwari's speech during Motion...   \n",
       "12924790  Shri La Ganesan's speech during Motion of Than...   \n",
       "12924791  Shri Mukhtar Abbas Naqvi's speech during Motio...   \n",
       "12924792  BJP submitted complaint to EC against Chief Se...   \n",
       "12924793  Shri Amit Shah speech at public meeting in Noi...   \n",
       "\n",
       "                  upload_date  view_count  \n",
       "12924789  2017-02-06 00:00:00      4409.0  \n",
       "12924790  2017-02-06 00:00:00      1172.0  \n",
       "12924791  2017-02-06 00:00:00      1898.0  \n",
       "12924792  2017-02-06 00:00:00       726.0  \n",
       "12924793  2017-02-06 00:00:00     37572.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_video_meta_4_parquet.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all parquet files into dask dataframes\n",
    "dd_video_meta_1_parquet = dd.read_parquet(path='YouNiverse/df_video_meta_1.gz')\n",
    "dd_video_meta_2_parquet = dd.read_parquet(path='YouNiverse/df_video_meta_2.gz')\n",
    "dd_video_meta_3_parquet = dd.read_parquet(path='YouNiverse/df_video_meta_3.gz')\n",
    "dd_video_meta_4_parquet = dd.read_parquet(path='YouNiverse/df_video_meta_4.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_parquet(path='YouNiverse/df_video_meta_1.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categories</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>crawl_date</th>\n",
       "      <th>description</th>\n",
       "      <th>dislike_count</th>\n",
       "      <th>display_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>like_count</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>view_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19999995</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UCbzt7jamo0xA0WKPX3Ut-rw</td>\n",
       "      <td>2019-11-15 03:58:54.691949</td>\n",
       "      <td>FACEBOOK PAGE\\nhttps://www.facebook.com/JamesH...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>jnfFTj85L8E</td>\n",
       "      <td>310</td>\n",
       "      <td>308.0</td>\n",
       "      <td>02,Escape,From,The,Tavern,James,Horner</td>\n",
       "      <td>02 - Escape From The Tavern - James Horner - W...</td>\n",
       "      <td>2011-07-21 00:00:00</td>\n",
       "      <td>123004.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999996</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UCbzt7jamo0xA0WKPX3Ut-rw</td>\n",
       "      <td>2019-11-15 03:58:55.296351</td>\n",
       "      <td>FACEBOOK PAGE\\nhttps://www.facebook.com/JamesH...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>pRskpDvjrIM</td>\n",
       "      <td>590</td>\n",
       "      <td>1346.0</td>\n",
       "      <td>01,Elora,Danan,James,Horner</td>\n",
       "      <td>01 - Elora Danan - James Horner - Willow</td>\n",
       "      <td>2011-07-21 00:00:00</td>\n",
       "      <td>308625.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999997</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UCbzt7jamo0xA0WKPX3Ut-rw</td>\n",
       "      <td>2019-11-15 03:58:55.940956</td>\n",
       "      <td>FACEBOOK PAGE\\nhttps://www.facebook.com/JamesH...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>SqggGvm_9a8</td>\n",
       "      <td>260</td>\n",
       "      <td>31.0</td>\n",
       "      <td>14,See,You,James,Horner</td>\n",
       "      <td>14 - I See You - Leona Lewis - James Horner - ...</td>\n",
       "      <td>2011-06-23 00:00:00</td>\n",
       "      <td>3432.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999998</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UCbzt7jamo0xA0WKPX3Ut-rw</td>\n",
       "      <td>2019-11-15 03:58:56.573328</td>\n",
       "      <td>FACEBOOK PAGE\\nhttps://www.facebook.com/JamesH...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Hjc5KhASGhI</td>\n",
       "      <td>680</td>\n",
       "      <td>21.0</td>\n",
       "      <td>13,War,James,Horner</td>\n",
       "      <td>13 - War - James Horner - Avatar</td>\n",
       "      <td>2011-06-23 00:00:00</td>\n",
       "      <td>3590.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999999</th>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>UCbzt7jamo0xA0WKPX3Ut-rw</td>\n",
       "      <td>2019-11-15 03:58:57.067663</td>\n",
       "      <td>FACEBOOK PAGE\\nhttps://www.facebook.com/JamesH...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9j4OXdEJBpc</td>\n",
       "      <td>310</td>\n",
       "      <td>36.0</td>\n",
       "      <td>12,Gathering,All,The,Na'vi,Clans,For,Battle,Ja...</td>\n",
       "      <td>12 - Gathering All The Na'vi Clans For Battle ...</td>\n",
       "      <td>2011-06-23 00:00:00</td>\n",
       "      <td>7562.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                categories                channel_id  \\\n",
       "19999995  Film & Animation  UCbzt7jamo0xA0WKPX3Ut-rw   \n",
       "19999996  Film & Animation  UCbzt7jamo0xA0WKPX3Ut-rw   \n",
       "19999997  Film & Animation  UCbzt7jamo0xA0WKPX3Ut-rw   \n",
       "19999998  Film & Animation  UCbzt7jamo0xA0WKPX3Ut-rw   \n",
       "19999999  Film & Animation  UCbzt7jamo0xA0WKPX3Ut-rw   \n",
       "\n",
       "                          crawl_date  \\\n",
       "19999995  2019-11-15 03:58:54.691949   \n",
       "19999996  2019-11-15 03:58:55.296351   \n",
       "19999997  2019-11-15 03:58:55.940956   \n",
       "19999998  2019-11-15 03:58:56.573328   \n",
       "19999999  2019-11-15 03:58:57.067663   \n",
       "\n",
       "                                                description  dislike_count  \\\n",
       "19999995  FACEBOOK PAGE\\nhttps://www.facebook.com/JamesH...            8.0   \n",
       "19999996  FACEBOOK PAGE\\nhttps://www.facebook.com/JamesH...           36.0   \n",
       "19999997  FACEBOOK PAGE\\nhttps://www.facebook.com/JamesH...            2.0   \n",
       "19999998  FACEBOOK PAGE\\nhttps://www.facebook.com/JamesH...            0.0   \n",
       "19999999  FACEBOOK PAGE\\nhttps://www.facebook.com/JamesH...            4.0   \n",
       "\n",
       "           display_id  duration  like_count  \\\n",
       "19999995  jnfFTj85L8E       310       308.0   \n",
       "19999996  pRskpDvjrIM       590      1346.0   \n",
       "19999997  SqggGvm_9a8       260        31.0   \n",
       "19999998  Hjc5KhASGhI       680        21.0   \n",
       "19999999  9j4OXdEJBpc       310        36.0   \n",
       "\n",
       "                                                       tags  \\\n",
       "19999995             02,Escape,From,The,Tavern,James,Horner   \n",
       "19999996                        01,Elora,Danan,James,Horner   \n",
       "19999997                            14,See,You,James,Horner   \n",
       "19999998                                13,War,James,Horner   \n",
       "19999999  12,Gathering,All,The,Na'vi,Clans,For,Battle,Ja...   \n",
       "\n",
       "                                                      title  \\\n",
       "19999995  02 - Escape From The Tavern - James Horner - W...   \n",
       "19999996           01 - Elora Danan - James Horner - Willow   \n",
       "19999997  14 - I See You - Leona Lewis - James Horner - ...   \n",
       "19999998                   13 - War - James Horner - Avatar   \n",
       "19999999  12 - Gathering All The Na'vi Clans For Battle ...   \n",
       "\n",
       "                  upload_date  view_count  \n",
       "19999995  2011-07-21 00:00:00    123004.0  \n",
       "19999996  2011-07-21 00:00:00    308625.0  \n",
       "19999997  2011-06-23 00:00:00      3432.0  \n",
       "19999998  2011-06-23 00:00:00      3590.0  \n",
       "19999999  2011-06-23 00:00:00      7562.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all dask dataframes into one\n",
    "dfs = [dd_video_meta_1_parquet, dd_video_meta_2_parquet, dd_video_meta_3_parquet, dd_video_meta_4_parquet]\n",
    "dd_parquet = dd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write all dask dataframes into a Parquet file containing all the video metadata\n",
    "dd.to_parquet(dd_parquet, path='YouNiverse/df_video_meta_parquet.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.00 MiB for an array with shape (131072,) and data type object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_video_meta \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYouNiverse/df_video_meta_parquet.gz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\MaxLo\\anaconda3\\envs\\VisualStudio\\Lib\\site-packages\\pandas\\io\\parquet.py:667\u001b[0m, in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[0;32m    664\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    665\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[1;32m--> 667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m impl\u001b[38;5;241m.\u001b[39mread(\n\u001b[0;32m    668\u001b[0m     path,\n\u001b[0;32m    669\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m    670\u001b[0m     filters\u001b[38;5;241m=\u001b[39mfilters,\n\u001b[0;32m    671\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    672\u001b[0m     use_nullable_dtypes\u001b[38;5;241m=\u001b[39muse_nullable_dtypes,\n\u001b[0;32m    673\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    674\u001b[0m     filesystem\u001b[38;5;241m=\u001b[39mfilesystem,\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    676\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\MaxLo\\anaconda3\\envs\\VisualStudio\\Lib\\site-packages\\pandas\\io\\parquet.py:281\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[1;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    274\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[0;32m    275\u001b[0m         path_or_handle,\n\u001b[0;32m    276\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 281\u001b[0m     result \u001b[38;5;241m=\u001b[39m pa_table\u001b[38;5;241m.\u001b[39mto_pandas(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mto_pandas_kwargs)\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    284\u001b[0m         result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m_as_manager(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\MaxLo\\anaconda3\\envs\\VisualStudio\\Lib\\site-packages\\pyarrow\\array.pxi:872\u001b[0m, in \u001b[0;36mpyarrow.lib._PandasConvertible.to_pandas\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\MaxLo\\anaconda3\\envs\\VisualStudio\\Lib\\site-packages\\pyarrow\\table.pxi:4904\u001b[0m, in \u001b[0;36mpyarrow.lib.Table._to_pandas\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\MaxLo\\anaconda3\\envs\\VisualStudio\\Lib\\site-packages\\pyarrow\\pandas_compat.py:795\u001b[0m, in \u001b[0;36mtable_to_dataframe\u001b[1;34m(options, table, categories, ignore_metadata, types_mapper)\u001b[0m\n\u001b[0;32m    792\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternals\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BlockManager\n\u001b[0;32m    793\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataFrame\n\u001b[1;32m--> 795\u001b[0m blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    796\u001b[0m     _reconstruct_block(item, column_names, ext_columns_dtypes)\n\u001b[0;32m    797\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m result\n\u001b[0;32m    798\u001b[0m ]\n\u001b[0;32m    799\u001b[0m axes \u001b[38;5;241m=\u001b[39m [columns, index]\n\u001b[0;32m    800\u001b[0m mgr \u001b[38;5;241m=\u001b[39m BlockManager(blocks, axes)\n",
      "File \u001b[1;32mc:\\Users\\MaxLo\\anaconda3\\envs\\VisualStudio\\Lib\\site-packages\\pyarrow\\pandas_compat.py:796\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    792\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternals\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BlockManager\n\u001b[0;32m    793\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataFrame\n\u001b[0;32m    795\u001b[0m blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 796\u001b[0m     _reconstruct_block(item, column_names, ext_columns_dtypes)\n\u001b[0;32m    797\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m result\n\u001b[0;32m    798\u001b[0m ]\n\u001b[0;32m    799\u001b[0m axes \u001b[38;5;241m=\u001b[39m [columns, index]\n\u001b[0;32m    800\u001b[0m mgr \u001b[38;5;241m=\u001b[39m BlockManager(blocks, axes)\n",
      "File \u001b[1;32mc:\\Users\\MaxLo\\anaconda3\\envs\\VisualStudio\\Lib\\site-packages\\pyarrow\\pandas_compat.py:738\u001b[0m, in \u001b[0;36m_reconstruct_block\u001b[1;34m(item, columns, extension_columns, return_block)\u001b[0m\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(pandas_dtype, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__from_arrow__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    736\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis column does not support to be converted \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    737\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto a pandas ExtensionArray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 738\u001b[0m     arr \u001b[38;5;241m=\u001b[39m pandas_dtype\u001b[38;5;241m.\u001b[39m__from_arrow__(arr)\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    740\u001b[0m     arr \u001b[38;5;241m=\u001b[39m block_arr\n",
      "File \u001b[1;32mc:\\Users\\MaxLo\\anaconda3\\envs\\VisualStudio\\Lib\\site-packages\\pandas\\core\\arrays\\string_.py:236\u001b[0m, in \u001b[0;36mStringDtype.__from_arrow__\u001b[1;34m(self, array)\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m chunks:\n\u001b[0;32m    233\u001b[0m         \u001b[38;5;66;03m# convert chunk by chunk to numpy and concatenate then, to avoid\u001b[39;00m\n\u001b[0;32m    234\u001b[0m         \u001b[38;5;66;03m# overflow for large string data when concatenating the pyarrow arrays\u001b[39;00m\n\u001b[0;32m    235\u001b[0m         arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mto_numpy(zero_copy_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 236\u001b[0m         arr \u001b[38;5;241m=\u001b[39m ensure_string_array(arr, na_value\u001b[38;5;241m=\u001b[39mlibmissing\u001b[38;5;241m.\u001b[39mNA)\n\u001b[0;32m    237\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(arr)\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunks) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mlib.pyx:720\u001b[0m, in \u001b[0;36mpandas._libs.lib.ensure_string_array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mlib.pyx:770\u001b[0m, in \u001b[0;36mpandas._libs.lib.ensure_string_array\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.00 MiB for an array with shape (131072,) and data type object"
     ]
    }
   ],
   "source": [
    "df_video_meta = pd.read_parquet(path='YouNiverse/df_video_meta_parquet.gz')\n",
    "# Crashed multiple times while running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_video_meta = dd.read_parquet(path='YouNiverse/df_video_meta_parquet.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categories</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>crawl_date</th>\n",
       "      <th>description</th>\n",
       "      <th>dislike_count</th>\n",
       "      <th>display_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>like_count</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>view_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2658</th>\n",
       "      <td>Music</td>\n",
       "      <td>UCzWfqsjlvzAOUozsGFR3kbg</td>\n",
       "      <td>2019-10-31 15:42:09.015401</td>\n",
       "      <td>Link to the FULL music video: http://www.youtu...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>WVapFh7cx3M</td>\n",
       "      <td>142</td>\n",
       "      <td>184.0</td>\n",
       "      <td>En Av oss,one of us,project,Gutterommet,music,...</td>\n",
       "      <td>My Biggest Project EVER! Music Video - En Av O...</td>\n",
       "      <td>2016-06-06 00:00:00</td>\n",
       "      <td>4360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3053</th>\n",
       "      <td>Music</td>\n",
       "      <td>UCzWfqsjlvzAOUozsGFR3kbg</td>\n",
       "      <td>2019-10-31 15:42:16.320706</td>\n",
       "      <td>Need Free Diamonds?  [ Clash Of Clans - Boom B...</td>\n",
       "      <td>126.0</td>\n",
       "      <td>IyfriHeXo3I</td>\n",
       "      <td>35</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>boom beach,boom beach general,bootramp,riflema...</td>\n",
       "      <td>Boom Beach General Song</td>\n",
       "      <td>2015-06-04 00:00:00</td>\n",
       "      <td>43190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3220</th>\n",
       "      <td>Music</td>\n",
       "      <td>UCzWfqsjlvzAOUozsGFR3kbg</td>\n",
       "      <td>2019-10-31 15:41:52.783564</td>\n",
       "      <td>Thank you Nordic Screens Norway for giving me ...</td>\n",
       "      <td>112.0</td>\n",
       "      <td>O0N0fH41wGw</td>\n",
       "      <td>140</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>official,music,boom beach,boom beach song,boom...</td>\n",
       "      <td>BRAVE | Boom Beach | Bootramp feat Kosteofficial</td>\n",
       "      <td>2015-01-05 00:00:00</td>\n",
       "      <td>41416.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3591</th>\n",
       "      <td>Music</td>\n",
       "      <td>UCzWdpFOflXTOk5Gsi2aJ67g</td>\n",
       "      <td>2019-11-13 21:46:26.995798</td>\n",
       "      <td>Subscribe for more horror music: https://www.y...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H20js4rsYeI</td>\n",
       "      <td>112</td>\n",
       "      <td>102.0</td>\n",
       "      <td>horror music,best horror music,scary music,cre...</td>\n",
       "      <td>Horror Trailer Music - The Terror | Atmospheri...</td>\n",
       "      <td>2019-10-02 00:00:00</td>\n",
       "      <td>2643.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592</th>\n",
       "      <td>Music</td>\n",
       "      <td>UCzWdpFOflXTOk5Gsi2aJ67g</td>\n",
       "      <td>2019-11-13 21:46:27.615035</td>\n",
       "      <td>Subscribe for more horror music: https://www.y...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bM06MQ--Daw</td>\n",
       "      <td>157</td>\n",
       "      <td>63.0</td>\n",
       "      <td>horror music,best horror music,scary music,cre...</td>\n",
       "      <td>Synapse Trailer Music - Padded Room | Epic Hyb...</td>\n",
       "      <td>2019-10-01 00:00:00</td>\n",
       "      <td>1304.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     categories                channel_id                  crawl_date  \\\n",
       "2658      Music  UCzWfqsjlvzAOUozsGFR3kbg  2019-10-31 15:42:09.015401   \n",
       "3053      Music  UCzWfqsjlvzAOUozsGFR3kbg  2019-10-31 15:42:16.320706   \n",
       "3220      Music  UCzWfqsjlvzAOUozsGFR3kbg  2019-10-31 15:41:52.783564   \n",
       "3591      Music  UCzWdpFOflXTOk5Gsi2aJ67g  2019-11-13 21:46:26.995798   \n",
       "3592      Music  UCzWdpFOflXTOk5Gsi2aJ67g  2019-11-13 21:46:27.615035   \n",
       "\n",
       "                                            description  dislike_count  \\\n",
       "2658  Link to the FULL music video: http://www.youtu...           28.0   \n",
       "3053  Need Free Diamonds?  [ Clash Of Clans - Boom B...          126.0   \n",
       "3220  Thank you Nordic Screens Norway for giving me ...          112.0   \n",
       "3591  Subscribe for more horror music: https://www.y...            0.0   \n",
       "3592  Subscribe for more horror music: https://www.y...            1.0   \n",
       "\n",
       "       display_id  duration  like_count  \\\n",
       "2658  WVapFh7cx3M       142       184.0   \n",
       "3053  IyfriHeXo3I        35      1037.0   \n",
       "3220  O0N0fH41wGw       140      1193.0   \n",
       "3591  H20js4rsYeI       112       102.0   \n",
       "3592  bM06MQ--Daw       157        63.0   \n",
       "\n",
       "                                                   tags  \\\n",
       "2658  En Av oss,one of us,project,Gutterommet,music,...   \n",
       "3053  boom beach,boom beach general,bootramp,riflema...   \n",
       "3220  official,music,boom beach,boom beach song,boom...   \n",
       "3591  horror music,best horror music,scary music,cre...   \n",
       "3592  horror music,best horror music,scary music,cre...   \n",
       "\n",
       "                                                  title          upload_date  \\\n",
       "2658  My Biggest Project EVER! Music Video - En Av O...  2016-06-06 00:00:00   \n",
       "3053                            Boom Beach General Song  2015-06-04 00:00:00   \n",
       "3220   BRAVE | Boom Beach | Bootramp feat Kosteofficial  2015-01-05 00:00:00   \n",
       "3591  Horror Trailer Music - The Terror | Atmospheri...  2019-10-02 00:00:00   \n",
       "3592  Synapse Trailer Music - Padded Room | Epic Hyb...  2019-10-01 00:00:00   \n",
       "\n",
       "      view_count  \n",
       "2658      4360.0  \n",
       "3053     43190.0  \n",
       "3220     41416.0  \n",
       "3591      2643.0  \n",
       "3592      1304.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd_video_meta.loc[dd_video_meta.categories=='Music'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categories</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>crawl_date</th>\n",
       "      <th>description</th>\n",
       "      <th>dislike_count</th>\n",
       "      <th>display_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>like_count</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>view_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>2019-10-31 20:19:38.143766</td>\n",
       "      <td>Subscribe for more: https://goo.gl/JI78Ak\n",
       "New ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6LvO-iX4FLw</td>\n",
       "      <td>193</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Hulk (Comic Book Character),Batman (Comic Book...</td>\n",
       "      <td>The Hulk wakes up by a Minions Batman DC Heroes</td>\n",
       "      <td>2015-11-01 00:00:00</td>\n",
       "      <td>865.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>2019-10-31 20:19:29.608486</td>\n",
       "      <td>Subscribe for more: https://goo.gl/JI78Ak\n",
       "New ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>ztT0SeQ28Eg</td>\n",
       "      <td>422</td>\n",
       "      <td>13.0</td>\n",
       "      <td>lego kids,lego pirates,lego animals,lego fores...</td>\n",
       "      <td>Lego Forest Movie for babies with  animals boa...</td>\n",
       "      <td>2015-09-12 00:00:00</td>\n",
       "      <td>13846.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>2019-10-31 20:19:30.199041</td>\n",
       "      <td>Subscribe for more: https://goo.gl/JI78Ak\n",
       "New ...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>O2TGCiUb01Y</td>\n",
       "      <td>300</td>\n",
       "      <td>71.0</td>\n",
       "      <td>lego circus,lego toys,lego juguetes,Lego train...</td>\n",
       "      <td>Lego Circus movie for kids with animals toys C...</td>\n",
       "      <td>2015-09-11 00:00:00</td>\n",
       "      <td>63887.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>2019-10-31 20:19:30.800639</td>\n",
       "      <td>Subscribe for more: https://goo.gl/JI78Ak\n",
       "New ...</td>\n",
       "      <td>46.0</td>\n",
       "      <td>j1plTifI4i4</td>\n",
       "      <td>648</td>\n",
       "      <td>442.0</td>\n",
       "      <td>lego kids,lego junior,lego fireman,lego city p...</td>\n",
       "      <td>Lego City police Lego fireman Cartoons about L...</td>\n",
       "      <td>2015-09-11 00:00:00</td>\n",
       "      <td>212832.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>UCzWrhkg9eK5I8Bm3HfV-unA</td>\n",
       "      <td>2019-10-31 20:19:31.440881</td>\n",
       "      <td>Lego Policia del pantano 60069\n",
       "Aqui tenemos la...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1Gvhx_KzSf0</td>\n",
       "      <td>676</td>\n",
       "      <td>39.0</td>\n",
       "      <td>lego,bricomania,piezas lego,lego policia,lego ...</td>\n",
       "      <td>Lego Policia del pantano 60069 Swamp Police</td>\n",
       "      <td>2015-09-04 00:00:00</td>\n",
       "      <td>12625.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        categories                channel_id                  crawl_date  \\\n",
       "265  Entertainment  UCzWrhkg9eK5I8Bm3HfV-unA  2019-10-31 20:19:38.143766   \n",
       "270  Entertainment  UCzWrhkg9eK5I8Bm3HfV-unA  2019-10-31 20:19:29.608486   \n",
       "271  Entertainment  UCzWrhkg9eK5I8Bm3HfV-unA  2019-10-31 20:19:30.199041   \n",
       "272  Entertainment  UCzWrhkg9eK5I8Bm3HfV-unA  2019-10-31 20:19:30.800639   \n",
       "273  Entertainment  UCzWrhkg9eK5I8Bm3HfV-unA  2019-10-31 20:19:31.440881   \n",
       "\n",
       "                                           description  dislike_count  \\\n",
       "265  Subscribe for more: https://goo.gl/JI78Ak\n",
       "New ...            0.0   \n",
       "270  Subscribe for more: https://goo.gl/JI78Ak\n",
       "New ...            5.0   \n",
       "271  Subscribe for more: https://goo.gl/JI78Ak\n",
       "New ...           21.0   \n",
       "272  Subscribe for more: https://goo.gl/JI78Ak\n",
       "New ...           46.0   \n",
       "273  Lego Policia del pantano 60069\n",
       "Aqui tenemos la...            5.0   \n",
       "\n",
       "      display_id  duration  like_count  \\\n",
       "265  6LvO-iX4FLw       193        10.0   \n",
       "270  ztT0SeQ28Eg       422        13.0   \n",
       "271  O2TGCiUb01Y       300        71.0   \n",
       "272  j1plTifI4i4       648       442.0   \n",
       "273  1Gvhx_KzSf0       676        39.0   \n",
       "\n",
       "                                                  tags  \\\n",
       "265  Hulk (Comic Book Character),Batman (Comic Book...   \n",
       "270  lego kids,lego pirates,lego animals,lego fores...   \n",
       "271  lego circus,lego toys,lego juguetes,Lego train...   \n",
       "272  lego kids,lego junior,lego fireman,lego city p...   \n",
       "273  lego,bricomania,piezas lego,lego policia,lego ...   \n",
       "\n",
       "                                                 title          upload_date  \\\n",
       "265    The Hulk wakes up by a Minions Batman DC Heroes  2015-11-01 00:00:00   \n",
       "270  Lego Forest Movie for babies with  animals boa...  2015-09-12 00:00:00   \n",
       "271  Lego Circus movie for kids with animals toys C...  2015-09-11 00:00:00   \n",
       "272  Lego City police Lego fireman Cartoons about L...  2015-09-11 00:00:00   \n",
       "273        Lego Policia del pantano 60069 Swamp Police  2015-09-04 00:00:00   \n",
       "\n",
       "     view_count  \n",
       "265       865.0  \n",
       "270     13846.0  \n",
       "271     63887.0  \n",
       "272    212832.0  \n",
       "273     12625.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd_video_meta.loc[dd_video_meta.categories=='Entertainment'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VisualStudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
